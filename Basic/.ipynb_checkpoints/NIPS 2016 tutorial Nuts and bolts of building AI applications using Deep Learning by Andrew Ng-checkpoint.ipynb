{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIPS 2016 tutorial:\n",
    "# \"Nuts and bolts of building AI applications using Deep Learning\" by Andrew Ng\n",
    "앤드류 응 nips 강연\n",
    "https://www.youtube.com/watch?v=wjqaz6m42wU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실전적인 팁 소개 \n",
    "많은 프로젝트에서 나타나는 common patterns\n",
    "\n",
    "Workflow guidelines\n",
    "다음 [link](https://github.com/thomasj02/DeepLearningProjectWorkflow/blob/master/README.md)에서 간단히 위의 workflow를 체험해볼 수 있습니다.\n",
    "\n",
    "### Abstract\n",
    "(from NIPS 2016 website)\n",
    "\n",
    "```\n",
    "How do you get deep learning to work in your business, product, or scientific study? The rise of highly scalable deep learning techniques is changing how you can best approach AI problems. This includes how you define your train/dev/test split, how you organize your data, how you should think through your search among promising model architectures, and even how you might develop new AI-enabled products. In this tutorial, you’ll learn about the emerging best practices in this nascent area. You’ll come away able to better organize your and your team’s work when developing deep learning applications.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "* Major DL trends\n",
    "* End-to-end DL\n",
    "* Bias/Variance\n",
    "* Mismatched train/test(new bias/variance)\n",
    "* AI Product Management\n",
    "* Personal advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major DL Trends\n",
    "\n",
    "### 왜 지금 딥러닝이 각광받고 있을까?\n",
    "양적 팽창이 큰 기여를 하고 있다.\n",
    "### Scale\n",
    "\n",
    "![Scale_driving_Deep_Learning_progress](image/Scale_driving_Deep_Learning_progress.PNG)\n",
    "제목 : #Scale   \n",
    "x축 : Data   \n",
    "y축 : Reference   \n",
    "\n",
    "위에서부터 차례대로 \n",
    "* large NN\n",
    "* Medium NN\n",
    "* Small NN\n",
    "* Traditional ML\n",
    "\n",
    "Traditional ML(like logistic regression,SVM,decision trees)은 learning capacity가 많은 양의 데이터를 제대로 capture하는데 충분치 못 하다. 데이터의 양이 어떤 임계점을 넘는 순간 더 이상 성능이 증가하지 않는 것을 볼 수 있습니다. \n",
    "우리 시대는 점점 더 디지털화되고 모바일 기기를 많이 쓴다.(데이터가 폭발적으로 증가) 빅데이터의 시대가 오면서 데이터의 양적 팽창으로 인한 잉여 정보로 성능 향상을 이뤄야 한다. 그러나 전통적인 ML 방법은 데이터를 더 넣어주더라도 성능이 더 증가하지 않는다\n",
    "몇년 전 작은 Neural network(NN)가 ML보다 살짝 나은 성능을 보여줌을 보았다\n",
    "중간 사이즈의 NN은 더 나은 성능을 보여준다\n",
    "그리고 더 큰 NN은 더 나은 성능을 보여줄 것이다.\n",
    "\n",
    "그러므로 현재 딥러닝이 각광받고 있는 이유는 scale 떄문이다\n",
    "1. scale of data\n",
    "2. scale in the size of NN\n",
    "\n",
    "Data가 적은 시대에서는 각 방법이 모두 비슷한 성능을 보였었다. 이 때는 성능에 데이터를 어떻게 다루는지(hand engineering skill, feature engineering)가 더 영향을 미쳤다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 당신이 3달 이내에 상품을 만들어야 한다면\n",
    "지금 상업적으로 가치가 있는 것은 Supervised Learning이다.(더 쉽게 상품을 만들 수 있다)\n",
    "* \"General\" NN(여기선 density connected neural networks를 의미)\n",
    "* Sequence Models(recurrent neural networks,GRU,LSTM,CTC 등) \n",
    "* Image Models(2D/3D) ConvNets 등\n",
    "\n",
    "Other(unsupervised learning, reinforcement learning)\n",
    "Unsupervised learning은 Supervised Learning보다도 훨씬 더 많은 데이터를 필요로 한다. 이 때문에 강화학습이 주로 playing games에 집중되어 있는데 무한히 시뮬레이션을 돌려 데이터를 얻을 수 있기 때문이다. 그래서 강화학습은 게임 밖에서 적용하기가 힘들다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝이 각광받는 이유 두번째\n",
    "### rise of end to end deep learning((Supervised) for complex outputs\n",
    "\n",
    "![The rise of end-to-end learning](image/The_rise_of_end_to_end_learning.PNG)\n",
    "\n",
    "\n",
    "몇 년전 ML은 classification이나 regression problem에 집중되어 있었다. 이전까지는 기계 학습이 다룰 수 있는 output 값이라 해봐야 분류를 위해 Class를 나타내는 정수나 확률을 나타내는 실수 정도뿐이었습니다. \n",
    "\n",
    "X -> Y   \n",
    "* movie review -> sentiments\n",
    "* image -> category\n",
    "\n",
    "이제 DL은 그냥 숫자보다 더 복잡한 output을 낸다.   \n",
    "Feature extraction 등의 여러 모듈로 이루어져있는 기존의 방법들과는 달리 입력을 받아 모든 일을 Neural Nets가 처리하여 결과를 출력하기 때문에 \"end-to-end\"라고 불립니다. 이런 모델이 너무 black-box 같아서 비판을 받기도 하지만 어찌 되었든 기존의 모델이 잘 해결하지 못하는 문제를 너무나도 잘 해결하기 때문에 큰 반향을 일으키고 있죠(예, 음성 인식) 이렇게 보면 뭔가 end-to-end learning이 모든 문제에 두루두루 적용이 가능한 만능 열쇠처럼 생각할 수도 있겠지만 사실 이 부분에서 Andrew 교수님이 방점을 두는 부분은 좀 더 조심스럽게 end-to-end 방식을 적용해야한다는 것입니다.\n",
    "\n",
    "즉, end-to-end learning 방식이 많은 문제에 대해 잘 통하기도 하지만 반대로 그렇지 않은 경우도 종종 볼 수 있다는 것이죠. 그런 예는 밑에서 살펴보겠습니다.\n",
    "\n",
    "* audio -> text(transciption)\n",
    "* image -> caption\n",
    "* Translation : english -> French \n",
    "* Text to Speech : text -> audio\n",
    "\n",
    "이것으로 더 다양한 시나리오를 만들 수 있다.\n",
    "\n",
    "Major  categories  of  DL  models\n",
    "\n",
    "1. General  neural  networks   \n",
    "2. Sequence  models  (1D  sequences)    \n",
    "    • RNN,  GRU,  LSTM,  CTC,  attention  models,  …. \n",
    "3. Image  models    \n",
    "    • 2D  and  3D  convolutional  networks \n",
    "4. Advanced/future  tech:    \n",
    "    • Unsupervised  learning  (sparse  coding,  ICA,  SFA,   …),  Reinforcement  learning,  ….  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End DL\n",
    "\n",
    "![Speech recognition](image/Speech_recognition.PNG)\n",
    "\n",
    "전통적인 speech recognition 구조는 매우 복잡했다.(very complex pipeline)\n",
    "audio -> features -> Phonemes(basic units of sound) -> Transcipt\n",
    "many intermediate stage를 가졌다\n",
    "\n",
    "반면에 End-to-end DL은\n",
    "audio -> DL -> Transcipt\n",
    "DL algorithm은 audio가 Transcipt로 되는 것을 바로 배운다\n",
    "\n",
    "밝혀진 바로는 많은 양의 labled data가 있을 시 DL이 더 낫다\n",
    "\n",
    "\n",
    "![Autonomous_driving](image/Autonomous_driving.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 수의 기업이 문에 얼굴인식을 달길 원한다. 많은 곳에서 개찰구에 사원증 같은 걸 찍고 나가는 데 이걸 얼굴인식으로 바꾸고 싶어하는 것이다.\n",
    "\n",
    "이걸 구현할 때 어떻게 하면 좋을까?\n",
    "무작정 카메라에 담긴 전체 이미지를 주고 학습시킬 수도 있다.(배경 + 사람 + 잡다한 것들) 그러나 더 효율적인 방법은 우선 face recognition을 이용하여 어떤 사람이 다가오고 있다는 것을 알고 그 얼굴 이미지를 확대하여 잘라낸 다음 그걸로 학습하는 것이다. \n",
    "\n",
    "좀 더 기술적으로 자세히 설명하자면 reference로 사원 Database에 등록된 얼굴을 사용한다. 그리고 이것과 새로 찍은 얼굴을 가지고 같은 사람인지 구별하게 하는 것이다.  \n",
    "\n",
    "왜 이렇게 구현하는 것일까??? 그 이유는 위의 전체 이미지를 가지고 판별하는 방법은 데이터가 별로 없기 때문이다. 반면 얼굴만 잘라낸 아래 방법은 데이터가 많다.(인터넷에서 얼굴만 잘라낸 이미지를 쉽게 많이 구할 수 있다) 그래서 회사에서 200M의 데이터를 구할 수 있었다. 하지만 위의 방법에 게이트로 다가오고 있는 사람의 데이터를 어디서 200M을 구할 수 있을까? \n",
    "\n",
    "End to End란 말처럼 아예 전처리도 필요로 하지 않는 경우는 많이 없다. end-to-end learning처럼 순수히 Neural nets이 모든 것을 알아서 해줄 것이라 생각하며 시도해서는 답이 없다고 말하는 쪽에 가까웠습니다.\n",
    "\n",
    "이어 딥러닝 방식이 적절한 데이터만 주어진다면 거의 항상 X에서 Y로 가는 함수를 학습할 수 있는 것은 맞지만 그렇다고 해서 그게 문제를 해결하는데 꼭 좋은 방법이냐는 것에는 동의할 수 없다고 덧붙였습니다.\n",
    "End-to-End works only when you have enough (x,y) data to learn function of needed level of complexity. \n",
    "이 부분은 정말 깊히 생각할 필요가 있는 것 같습니다. 실제 상황에 적용을 할 때 무작정 DL이 모든 것을 해결해줄 것이라 믿으면 안 된다는 것은 모두 동의하실 것입니다. 이렇게 정리해서 얘기하기도 사실 좀 우스워 보입니다만 실제 정책이나 큰 프로젝트들이 진행되는 것을 보면 꼭 그렇지도 않아보입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthcare   \n",
    "    x-ray of child hand -> estimate age\n",
    "\n",
    "    Traditional : Image -> Bones Feature(length 등) -> age\n",
    "    End to End : Image -> age\n",
    "\n",
    "    Image -> Bones Feature는 많은 데이터가 있지만 Image -> age는 데이터가 별로 없다.\n",
    "\n",
    "\n",
    "* 자율 주행   \n",
    "    Image -> cars, pedestrian -> Plan route -> Steering\n",
    "\n",
    "    Image -> cars, pedestrian 은 데이터가 많지만 image -> Steering은 데이터가 별로 없다.\n",
    "\n",
    "\n",
    "* Chat bot\n",
    "    text -> response 몇 개의 잘 된 경우가 있지만 잘 안 된다.\n",
    "\n",
    "    text -> inference engine -> response 이 더 잘 된다. 그러나 End to End는 아니다.\n",
    "\n",
    "**그래서 어딜 endpoints로 정하는 지가 중요하다.**\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias/Variance\n",
    "\n",
    "Machine  Learning  Strategy    \n",
    "    Often  you  will  have  a  lot  of  ideas  for  how  to  improve  an   AI  system,  what  do  you  do?     \n",
    "    Good  strategy  will  help  avoid  months  of  wasted  effort.\n",
    "\n",
    "\n",
    "목표가 사람 수준의 음성 인식이라고 하자   \n",
    "Goal : Build human-level speech recognition system\n",
    "\n",
    "![bias/variance](image/bias_variance.PNG)\n",
    "\n",
    "Train(60%) : NN으로 학습   \n",
    "Dev(20%) : tune parameters    \n",
    "Test(20%) : value performance   \n",
    "\n",
    "Human-level error : 1%               \n",
    "Training set error : 5%   \n",
    "Dev set error : 8%\n",
    "\n",
    "이 결과가 말해주는 것은 Training에서도 Human-level보다 못 하다 곧 test에서는 더 못 할 것이다. 그래서 이 때 당신은 이 차이를 줄이는 데 집중하는 것이 더 좋다 다른 작업보다.\n",
    "\n",
    "Human-level error와 Training set error의 차이를 Avoidable bias라 하자   \n",
    "Training set error와 Dev set error의 차이를 Variance라 하자(얼마나 일반화(generalizing)을 잘 했는가 Training data와 Not Training data 비교해 봤을 때)\n",
    "\n",
    "다른 예시로   \n",
    "Human-level error : 1%               \n",
    "Training set error : 2%\n",
    "Dev set error : 6%   \n",
    "라면 overfitting일수도 있다. 왜냐하면 Training 때 거의 Human-level이 될만큼 잘 했는데 Dev를 보면 generalizing이 안 됐다. 그래서 overfitting일수도 있다. \n",
    "\n",
    "Human-level error : 1%               \n",
    "Training set error : 6%\n",
    "Dev set error : 6%  \n",
    "high bias & high variance인 경우\n",
    "\n",
    "![Basic_recipe_for_machine_learning](image/Basic_recipe_for_machine_learning.PNG)\n",
    "\n",
    "* Bias Problem :    \n",
    "Training error high -> Bigger model, Train longer, try different optimizer, new model architecture\n",
    "\n",
    "* Variance Problem :    \n",
    "Dev error high -> More data, Regularization, New models architecture\n",
    "\n",
    "Bias와 Variance는 Trade off 관계인데 다른 쪽에 영향을 안 끼치고 둘 다 줄일 수 있는 마법적인 방법은 Bigger Model과 More Data이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연구를 하다보면 Human level performance까지는 금새 연구가 진척되다가 그 근방에 가까이 갈수록 점점 느려지다가 심지어 멈추는 경우가 생기는 것을 종종 보곤합니다. 왜 그럴까요?\n",
    "\n",
    "* Label is made by human (so the limit lies here)\n",
    "* Maybe because human level error is close to the optimal error (Bayes error, theoretical limit)\n",
    "\n",
    "그럼 이후에는 딱히 방법이 없는 것일까요? 쉽지는 않지만 그 때부터는 모델이 사람보다 잘 못하는 문제들을 모아서 (마치 오답노트처럼) 그 부분에 대한 약점을 집중적으로 학습시키는 방법 등이 사용된다고 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data synthesis\n",
    "데이터 합성(왜냐하면 DL은 많은 데이터를 필요로하기 때문이다)   \n",
    "유용한 경우가 있고 아주 쓸모 없는 경우가 있다.    \n",
    "\n",
    "Automatic data synthesis examples\n",
    "* OCR   \n",
    "    Text against random backgrounds   \n",
    "       \n",
    "       \n",
    "* Speech recognition   \n",
    "    Synthesize clean audio against different background noise\n",
    "       \n",
    "       \n",
    "* NLP : Grammar correction   \n",
    "    Synthesize random grammatical errors\n",
    "       \n",
    "   \n",
    "Sometimes synthesized data that appears great to human eyes is actually very impoverished in the eyes of ML algorithms, and covers only a minuscule fraction of the actual distribution of data E.g. images of cars extracted from video games.\n",
    "\n",
    "OCR(Optical character recognition)의 경우를 보자   \n",
    "많은 양의 데이터를 만드는 방법으로 random background + random text + random font + random word art(ppt 같은 데서 글자를 그림처럼 만드는 것 휘거나, 비틀리거나 입체적으로 등등)가 있다. 이 데이터로 원래 내용을 인식하는 것이다. \n",
    "\n",
    "이 모델은 성능이 잘 나왔는데 나중에 알고보니 distribution of colors가 dev set과 test set이 유사하였다.\n",
    "\n",
    "많은 사람들의 synthesis에서 다음과 같은 경우를 보았다. 처음엔 아무런 payoff가 없다가 그들이 어떤 trick을 발견하면 성능이 아주 잘 나오는 것이다. \n",
    "\n",
    "다른 예로는 speech recognition이 있는데 clean audio에선 성능이 잘 나오는 것에 그냥 background noise를 더하는 것이다. 이것은 sound wave의 중첩 특성을 이용한 것이다. 이러면 차 안에서 말하는 소리라던지 많은 양의 데이터를 만들 수 있다. \n",
    "\n",
    "다른 예로 NLP에서 grammar correction이 있다. 영어 문장에 random grammar를 더하는 것이다. random grammatical effect, random grammatical error를 보는 것이다. 인공지능이 ungrammatical sentence를 고치게 하는 것이다.\n",
    "\n",
    "Noise synthesis를 보자, 우리 팀은 10,000 hours의 clean audio data를 가지고 있고 10 hours 의 noise(inside car, cafe 등)를 가지고 있따. clean audio만 가지고 학습하면 overfitting이 되기 쉽다. 그러나 noise를 추가하면 많은 다른 경우를 만들 수 있다.\n",
    "\n",
    "다른 경우로는 recognize car가 있다. 어디서 많은 양의 car picture data를 얻을 것인가 예를 들어 GTA란 게임을 보자 거기엔 많은 양의 차량이 있다 거기서 얻어 보는 것은 어떤가 게임에는 20종류의 모델의 차량이 있다. 실제 게임을 해본다면 차가 20종류 밖에 안되는 것을 알지 못할 것이다. 실제 현실에는 20종류보다는 훨씬 많은 종류의 차량이 있다. 인간의 눈으로 봤을 땐 잘 모르지만 인공지능 모델에선 쉽게 overfitting된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train과 test set이 같은 distribution에서 나오면 이론을 증명하는데 더 좋을 것이다. 한 가지 예를 보자 당신은 speech enabled rear mirror 상품을 만들려고 하고 있다. 당신은 real mirror에게 스타벅스에 가는 데 방향을 알려줘라고 말할 수 있을 것이다. \n",
    "\n",
    "어떻게 speech recognition system을 만들 것인가   \n",
    "당신은 50,000 시간의 general speech data를 가지고 있을 수 있다.   \n",
    "거기에 추가로 10 시간의 rear view mirro data를 모았을 수도 있다.   \n",
    "문제는 이거다. 어떻게 이 문제에 대한 training,development,test set을 를 정의할 것인가\n",
    "\n",
    "![Different training and test set distributions](image/Different_training_and_test_set_distributions.PNG)\n",
    "\n",
    "한 가지 방법으로   \n",
    "50,000 시간 데이터를 쪼개 train과 dev로 만들고   \n",
    "10 시간 데이터를 test로 쓰는 방법이 있다.   \n",
    "이 방법은 안 좋은 것으로 밝혀졌다. 왜냐하면 test set과 dev set이 같은 distribution에서 나오지 않았기 때문이다. 우리가 신경써야할 test distribution에 generalize하지 못 했다. \n",
    "\n",
    "추천하는 방법으로는\n",
    "50,000 시간 데이터 중 작은 부분을 train-dev set으로 만들고   \n",
    "10 시간 데이터를 쪼개 dev,test set으로 만드는 것이다. 여기서 중요한 것은 dev와 test set이 같은 distribution에서 나왔다는 것이다. dev, test set를 단지 평가용으로 꽤 작게 설정하는데 성능을 향상시킬만큼 충분한 양이 있어야 한다. \n",
    "\n",
    "예를 들어 다음과 같이 error가 나왔다고 하자.  \n",
    "![error definition](image/error_definition.PNG)\n",
    "\n",
    "Human level error 1%   \n",
    "Training 10%   \n",
    "Training-Dev 10%   \n",
    "Dev 10%   \n",
    "Test 10%      \n",
    "\n",
    "Human level과 training의 차이는 bias이다. avoidable bias이다. Training과 Training-Dev의 차이는 variance이다. 다시 말하지만 training과 train-dev는 같은 distribution에서 나왔다. Training-dev와 Dev의 차이는 data mismatch issue이다. Training-Dev와 Dev 둘 다 훈련에 사용되지 않았지만 다른 Distribution에서 나왔다. 마지막으로 Dev와 Test의 차이는 overfit dev set이다. Dev와 Test는 같은 Distribution에서 나왔다.\n",
    "\n",
    "다른 예로\n",
    "Human level error 1%   \n",
    "Training 1%   \n",
    "Training-Dev 2%\n",
    "Dev 10%\n",
    "Test 11%\n",
    "\n",
    "당신은 Training-Dev와 Dev 사이의 엄청난 gap을 볼 수 있을 것이다. 이것은 당신의 에러 대부분이 data mismatch에서 왔음을 알 수 있다.\n",
    "\n",
    "에러를 수정하는 방법을 보자면\n",
    "![New recipe for machine learning](image/New_recipe_for_machine_learning.PNG)\n",
    "1. Training error(Bias Problem)   \n",
    "    Bigger Model, Train longer, New Model Architecture\n",
    "       \n",
    "       \n",
    "2. Training-Dev error(Variance Problem)   \n",
    "    같은 Distribution에서 나온 것도 제대로 못 함   \n",
    "    More Data, Regularization, New Model Architecture\n",
    "       \n",
    "       \n",
    "3. Dev error(Data Mismatch)   \n",
    "    다른 Distribution   \n",
    "    Make data more similar, Data synthesis, domain adaptation, New Model architecture)\n",
    "    \n",
    "       \n",
    "4. Test error(overfit dev set)   \n",
    "    같은 Distribution    \n",
    "    More dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![General Human/Bias/Variance analysis](image/General_Human_Bias_Variance_analysis.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Human  level  performance](image/Human_level_performance.PNG)\n",
    "\n",
    "위에서 Human level error가 1%라면 bias problem이다. 그러나 7.5%라면 variance problem이다. 이렇듯이 Human level error에 따라 문제가 달라지므로 Human level이 어떤지 아는 것이 중요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Medical imaging](image/Medical_imaging.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Product Management\n",
    "The  availability  of  new  supervised  DL  algorithms  means  we’re  rethinking  the  workflow   of  how  to  have  teams  collaborate  to  build  applications  using  DL.  A  Product  Manager   (PM)  can  help  an  AI  team  prioritize  the  most  fruitful  ML  tasks.  E.g.,  should  you   improve  speech  performance  with  car  noise,  café  noise,  for  low-­bandwidth  audio,  for   accented  speech,  or  improve  latency,  reduce  binary  size,  or  something  else?\n",
    "\n",
    "\n",
    "What  can  AI  do  today?  Some  heuristics  for  PMs:  \n",
    "    • If  a  typical  person  can  do  a  mental  task  with  less  than  one  second  of  thought,  we   can  probably  automate  it  using  AI  either  now  or  in  the  near  future.  \n",
    "    • For  any  concrete,  repeated  event  that  we  observe  (e.g.,  whether  user  clicks  on  ad;;   how  long  it  takes  to  deliver  a  package;;  ….),  we  can  reasonably  try  to  predict  the   outcome  of  the  next  event  (whether  user  clicks  on  next  ad).  \n",
    "\n",
    "![AI Product Management](image/AI_Product_Management.PNG)\n",
    "\n",
    "\n",
    "Product Manager(PM) is responsible for figuring out what products users really want\n",
    "How big the size the image, How important is latency\n",
    "\n",
    "User - PM - Engineer\n",
    "\n",
    "PM은 유저가 원하는 것을 알고 엔지니어에게 전달한다(구체적으로 이런 버튼이 여기에 이런 크기로 있었으면 좋겠고 이 버튼은 여기에....) \n",
    "\n",
    "AI에서는 상품을 뭘로 정의할것인지, 어떻게 디자인할 것인지 정하는 게 중요하다\n",
    "\n",
    "예를 들어 speech recognition을 보자 당신은 성능을 향상시키는 데 어떤 걸 향상시켜야할지 정해야 한다. 어떤 걸 제일 먼저 주력해서 해야할 지 정해야한다.\n",
    "* Noisy environment(Car, Cafe)\n",
    "* Low bandwidth audio\n",
    "* accented speech\n",
    "* Latency\n",
    "* binary size(모바일 환경에서는 큰 용량을 사용하기 힘듬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine  Learning  Yearning\n",
    "\n",
    "Book  on  AI/ML  technical  strategy.   \n",
    "Sign  up  at  http://mlyearning.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
