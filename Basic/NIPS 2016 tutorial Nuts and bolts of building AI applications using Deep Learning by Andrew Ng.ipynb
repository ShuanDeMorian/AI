{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIPS 2016 tutorial:\n",
    "# \"Nuts and bolts of building AI applications using Deep Learning\" by Andrew Ng\n",
    "앤드류 응 nips 강연\n",
    "https://www.youtube.com/watch?v=wjqaz6m42wU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실전적인 팁 소개 \n",
    "많은 프로젝트에서 나타나는 common patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "* Major DL trends\n",
    "* End-to-end DL\n",
    "* Bias/Variance\n",
    "* Mismatched train/test(new bias/variance)\n",
    "* AI Product Management\n",
    "* Personal advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major DL Trends\n",
    "\n",
    "### 왜 지금 딥러닝이 각광받고 있을까?\n",
    "### Scale\n",
    "\n",
    "![DL_Trends](image/DL_Trends.PNG)\n",
    "제목 : #Scale   \n",
    "x축 : Data   \n",
    "y축 : Reference   \n",
    "\n",
    "위에서부터 차례대로 \n",
    "* large NN\n",
    "* Medium NN\n",
    "* Small NN\n",
    "* Traditional ML\n",
    "\n",
    "Traditional ML(like logistic regression,SVM,decision trees)은 learning capacity가 많은 양의 데이터를 제대로 capture하는데 충분치 못 하다.\n",
    "우리 시대는 점점 더 디지털화되고 모바일 기기를 많이 쓴다.(데이터가 폭발적으로 증가)\n",
    "그러나 전통적인 ML 방법은 데이터를 더 넣어주더라도 성능이 더 증가하지 않는다\n",
    "몇년 전 작은 Neural network(NN)가 ML보다 살짝 나은 성능을 보여줌을 보았다\n",
    "중간 사이즈의 NN은 더 나은 성능을 보여준다\n",
    "그리고 더 큰 NN은 더 나은 성능을 보여줄 것이다.\n",
    "\n",
    "그러므로 현재 딥러닝이 각광받고 있는 이유는 scale 떄문이다\n",
    "1. scale of data\n",
    "2. scale in the size of NN\n",
    "\n",
    "Data가 적은 시대에서는 각 방법이 모두 비슷한 성능을 보였었다. 이 때는 성능에 데이터를 어떻게 다루는지(hand engineering skill, feature engineering)가 더 영향을 미쳤다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 당신이 3달 이내에 상품을 만들어야 한다면\n",
    "지금 상업적으로 가치가 있는 것은 Supervised Learning이다.(더 쉽게 상품을 만들 수 있다)\n",
    "* \"General\" NN(여기선 density connected neural networks를 의미)\n",
    "* Sequence Models(recurrent neural networks,GRU,LSTM,CTC 등) \n",
    "* Image Models(2D/3D) ConvNets 등\n",
    "\n",
    "Other(unsupervised learning, reinforcement learning)\n",
    "Unsupervised learning은 Supervised Learning보다도 훨씬 더 많은 데이터를 필요로 한다. 이 때문에 강화학습이 주로 playing games에 집중되어 있는데 무한히 시뮬레이션을 돌려 데이터를 얻을 수 있기 때문이다. 그래서 강화학습은 게임 밖에서 적용하기가 힘들다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝이 각광받는 이유 두번째\n",
    "### rise of end to end deep learning((Supervised) for complex outputs\n",
    "\n",
    "\n",
    "몇 년전 ML은 classification이나 regression problem에 집중되어 있었다.\n",
    "\n",
    "X -> Y   \n",
    "* movie review -> sentiments\n",
    "* image -> category\n",
    "\n",
    "이제 DL은 그냥 숫자보다 더 복잡한 output을 낸다.\n",
    "\n",
    "* audio -> text(transciption)\n",
    "* image -> caption\n",
    "* Translation : english -> French \n",
    "* Text to Speech : text -> audio\n",
    "\n",
    "이것으로 더 다양한 시나리오를 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End DL\n",
    "\n",
    "전통적인 speech recognition 구조는 매우 복잡했다.(very complex pipeline)\n",
    "audio -> features -> Phonemes(basic units of sound) -> Transcipt\n",
    "many intermediate stage를 가졌다\n",
    "\n",
    "반면에 End-to-end DL은\n",
    "audio -> DL -> Transcipt\n",
    "DL algorithm은 audio가 Transcipt로 되는 것을 바로 배운다\n",
    "\n",
    "밝혀진 바로는 많은 양의 labled data가 있을 시 DL이 더 낫다\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 수의 기업이 문에 얼굴인식을 달길 원한다. 많은 곳에서 개찰구에 사원증 같은 걸 찍고 나가는 데 이걸 얼굴인식으로 바꾸고 싶어하는 것이다.\n",
    "\n",
    "이걸 구현할 때 어떻게 하면 좋을까?\n",
    "무작정 카메라에 담긴 전체 이미지를 주고 학습시킬 수도 있다.(배경 + 사람 + 잡다한 것들) 그러나 더 효율적인 방법은 우선 face recognition을 이용하여 어떤 사람이 다가오고 있다는 것을 알고 그 얼굴 이미지를 확대하여 잘라낸 다음 그걸로 학습하는 것이다. \n",
    "\n",
    "좀 더 기술적으로 자세히 설명하자면 reference로 사원 Database에 등록된 얼굴을 사용한다. 그리고 이것과 새로 찍은 얼굴을 가지고 같은 사람인지 구별하게 하는 것이다.  \n",
    "\n",
    "왜 이렇게 구현하는 것일까??? 그 이유는 위의 전체 이미지를 가지고 판별하는 방법은 데이터가 별로 없기 때문이다. 반면 얼굴만 잘라낸 아래 방법은 데이터가 많다.(인터넷에서 얼굴만 잘라낸 이미지를 쉽게 많이 구할 수 있다) 그래서 회사에서 200M의 데이터를 구할 수 있었다. 하지만 위의 방법에 게이트로 다가오고 있는 사람의 데이터를 어디서 200M을 구할 수 있을까? \n",
    "\n",
    "End to End란 말처럼 아예 전처리도 필요로 하지 않는 경우는 많이 없다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Healthcare \n",
    "\n",
    "x-ray of child hand -> estimate age\n",
    "\n",
    "Traditional : Image -> Bones Feature(length 등) -> age\n",
    "End to End : Image -> age\n",
    "\n",
    "Image -> Bones Feature는 많은 데이터가 있지만 Image -> age는 데이터가 별로 없다.\n",
    "\n",
    "\n",
    "자율 주행   \n",
    "Image -> cars, pedestrian -> Plan route -> Steering\n",
    "\n",
    "Image -> cars, pedestrian 은 데이터가 많지만 image -> Steering은 데이터가 별로 없다.\n",
    "\n",
    "\n",
    "Chat bot\n",
    "text -> response 몇 개의 잘 된 경우가 있지만 잘 안 된다.\n",
    "\n",
    "text -> inference engine -> response 이 더 잘 된다. 그러나 End to End는 아니다.\n",
    "\n",
    "**그래서 어딜 endpoints로 정하는 지가 중요하다.**\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
