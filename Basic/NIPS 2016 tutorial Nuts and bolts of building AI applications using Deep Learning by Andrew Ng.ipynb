{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIPS 2016 tutorial:\n",
    "# \"Nuts and bolts of building AI applications using Deep Learning\" by Andrew Ng\n",
    "앤드류 응 nips 강연\n",
    "https://www.youtube.com/watch?v=wjqaz6m42wU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실전적인 팁 소개 \n",
    "많은 프로젝트에서 나타나는 common patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "* Major DL trends\n",
    "* End-to-end DL\n",
    "* Bias/Variance\n",
    "* Mismatched train/test(new bias/variance)\n",
    "* AI Product Management\n",
    "* Personal advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major DL Trends\n",
    "\n",
    "### 왜 지금 딥러닝이 각광받고 있을까?\n",
    "### Scale\n",
    "\n",
    "![DL_Trends](image/DL_Trends.PNG)\n",
    "제목 : #Scale   \n",
    "x축 : Data   \n",
    "y축 : Reference   \n",
    "\n",
    "위에서부터 차례대로 \n",
    "* large NN\n",
    "* Medium NN\n",
    "* Small NN\n",
    "* Traditional ML\n",
    "\n",
    "Traditional ML(like logistic regression,SVM,decision trees)은 learning capacity가 많은 양의 데이터를 제대로 capture하는데 충분치 못 하다.\n",
    "우리 시대는 점점 더 디지털화되고 모바일 기기를 많이 쓴다.(데이터가 폭발적으로 증가)\n",
    "그러나 전통적인 ML 방법은 데이터를 더 넣어주더라도 성능이 더 증가하지 않는다\n",
    "몇년 전 작은 Neural network(NN)가 ML보다 살짝 나은 성능을 보여줌을 보았다\n",
    "중간 사이즈의 NN은 더 나은 성능을 보여준다\n",
    "그리고 더 큰 NN은 더 나은 성능을 보여줄 것이다.\n",
    "\n",
    "그러므로 현재 딥러닝이 각광받고 있는 이유는 scale 떄문이다\n",
    "1. scale of data\n",
    "2. scale in the size of NN\n",
    "\n",
    "Data가 적은 시대에서는 각 방법이 모두 비슷한 성능을 보였었다. 이 때는 성능에 데이터를 어떻게 다루는지(hand engineering skill, feature engineering)가 더 영향을 미쳤다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 당신이 3달 이내에 상품을 만들어야 한다면\n",
    "지금 상업적으로 가치가 있는 것은 Supervised Learning이다.(더 쉽게 상품을 만들 수 있다)\n",
    "* \"General\" NN(여기선 density connected neural networks를 의미)\n",
    "* Sequence Models(recurrent neural networks,GRU,LSTM,CTC 등) \n",
    "* Image Models(2D/3D) ConvNets 등\n",
    "\n",
    "Other(unsupervised learning, reinforcement learning)\n",
    "Unsupervised learning은 Supervised Learning보다도 훨씬 더 많은 데이터를 필요로 한다. 이 때문에 강화학습이 주로 playing games에 집중되어 있는데 무한히 시뮬레이션을 돌려 데이터를 얻을 수 있기 때문이다. 그래서 강화학습은 게임 밖에서 적용하기가 힘들다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝이 각광받는 이유 두번째\n",
    "### rise of end to end deep learning((Supervised) for complex outputs\n",
    "\n",
    "\n",
    "몇 년전 ML은 classification이나 regression problem에 집중되어 있었다.\n",
    "\n",
    "X -> Y   \n",
    "* movie review -> sentiments\n",
    "* image -> category\n",
    "\n",
    "이제 DL은 그냥 숫자보다 더 복잡한 output을 낸다.\n",
    "\n",
    "* audio -> text(transciption)\n",
    "* image -> caption\n",
    "* Translation : english -> French \n",
    "* Text to Speech : text -> audio\n",
    "\n",
    "이것으로 더 다양한 시나리오를 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End DL\n",
    "\n",
    "전통적인 speech recognition 구조는 매우 복잡했다.(very complex pipeline)\n",
    "audio -> features -> Phonemes(basic units of sound) -> Transcipt\n",
    "many intermediate stage를 가졌다\n",
    "\n",
    "반면에 End-to-end DL은\n",
    "audio -> DL -> Transcipt\n",
    "DL algorithm은 audio가 Transcipt로 되는 것을 바로 배운다\n",
    "\n",
    "밝혀진 바로는 많은 양의 labled data가 있을 시 DL이 더 낫다\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 수의 기업이 문에 얼굴인식을 달길 원한다. 많은 곳에서 개찰구에 사원증 같은 걸 찍고 나가는 데 이걸 얼굴인식으로 바꾸고 싶어하는 것이다.\n",
    "\n",
    "이걸 구현할 때 어떻게 하면 좋을까?\n",
    "무작정 카메라에 담긴 전체 이미지를 주고 학습시킬 수도 있다.(배경 + 사람 + 잡다한 것들) 그러나 더 효율적인 방법은 우선 face recognition을 이용하여 어떤 사람이 다가오고 있다는 것을 알고 그 얼굴 이미지를 확대하여 잘라낸 다음 그걸로 학습하는 것이다. \n",
    "\n",
    "좀 더 기술적으로 자세히 설명하자면 reference로 사원 Database에 등록된 얼굴을 사용한다. 그리고 이것과 새로 찍은 얼굴을 가지고 같은 사람인지 구별하게 하는 것이다.  \n",
    "\n",
    "왜 이렇게 구현하는 것일까??? 그 이유는 위의 전체 이미지를 가지고 판별하는 방법은 데이터가 별로 없기 때문이다. 반면 얼굴만 잘라낸 아래 방법은 데이터가 많다.(인터넷에서 얼굴만 잘라낸 이미지를 쉽게 많이 구할 수 있다) 그래서 회사에서 200M의 데이터를 구할 수 있었다. 하지만 위의 방법에 게이트로 다가오고 있는 사람의 데이터를 어디서 200M을 구할 수 있을까? \n",
    "\n",
    "End to End란 말처럼 아예 전처리도 필요로 하지 않는 경우는 많이 없다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthcare   \n",
    "    x-ray of child hand -> estimate age\n",
    "\n",
    "    Traditional : Image -> Bones Feature(length 등) -> age\n",
    "    End to End : Image -> age\n",
    "\n",
    "    Image -> Bones Feature는 많은 데이터가 있지만 Image -> age는 데이터가 별로 없다.\n",
    "\n",
    "\n",
    "* 자율 주행   \n",
    "    Image -> cars, pedestrian -> Plan route -> Steering\n",
    "\n",
    "    Image -> cars, pedestrian 은 데이터가 많지만 image -> Steering은 데이터가 별로 없다.\n",
    "\n",
    "\n",
    "* Chat bot\n",
    "    text -> response 몇 개의 잘 된 경우가 있지만 잘 안 된다.\n",
    "\n",
    "    text -> inference engine -> response 이 더 잘 된다. 그러나 End to End는 아니다.\n",
    "\n",
    "**그래서 어딜 endpoints로 정하는 지가 중요하다.**\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias/Variance\n",
    "\n",
    "목표가 사람 수준의 음성 인식이라고 하자   \n",
    "Goal : Build human-level speech recognition system\n",
    "\n",
    "Train(60%) : NN으로 학습\n",
    "Dev(20%) : tune parameters \n",
    "Test(20%) : value performance\n",
    "\n",
    "Human-level error : 1%               \n",
    "Training set error : 5%\n",
    "Dev set error : 6%\n",
    "\n",
    "이 결과가 말해주는 것은 Training에서도 Human-level보다 못 하다 곧 test에서는 더 못 할 것이다. 그래서 이 때 당신은 이 차이를 줄이는 데 집중하는 것이 더 좋다 다른 작업보다.\n",
    "\n",
    "Human-level error와 Training set error의 차이를 Avoidable bias라 하자   \n",
    "Training set error와 Dev set error의 차이를 Variance라 하자(얼마나 일반화(generalizing)을 잘 했는가 Training data와 Not Training data 비교해 봤을 때)\n",
    "\n",
    "다른 예시로   \n",
    "Human-level error : 1%               \n",
    "Training set error : 2%\n",
    "Dev set error : 6%   \n",
    "라면 overfitting일수도 있다. 왜냐하면 Training 때 거의 Human-level이 될만큼 잘 했는데 Dev를 보면 generalizing이 안 됐다. 그래서 overfitting일수도 있다. \n",
    "\n",
    "Human-level error : 1%               \n",
    "Training set error : 6%\n",
    "Dev set error : 6%  \n",
    "high bias & high variance인 경우\n",
    "\n",
    "\n",
    "* Bias Problem :    \n",
    "Training error high -> Bigger model, Train longer, try different optimizer, new model architecture\n",
    "\n",
    "* Variance Problem :    \n",
    "Dev error high -> More data, Regularization, New models architecture\n",
    "\n",
    "Bias와 Variance는 Trade off 관계인데 다른 쪽에 영향을 안 끼치고 둘 다 줄일 수 있는 마법적인 방법은 Bigger Model과 More Data이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data synthesis\n",
    "데이터 합성(왜냐하면 DL은 많은 데이터를 필요로하기 때문이다)   \n",
    "유용한 경우가 있고 아주 쓸모 없는 경우가 있다.    \n",
    "\n",
    "OCR(Optical character recognition)의 경우를 보자   \n",
    "많은 양의 데이터를 만드는 방법으로 random background + random text + random font + random word art(ppt 같은 데서 글자를 그림처럼 만드는 것 휘거나, 비틀리거나 입체적으로 등등)가 있다. 이 데이터로 원래 내용을 인식하는 것이다. \n",
    "\n",
    "이 모델은 성능이 잘 나왔는데 나중에 알고보니 distribution of colors가 dev set과 test set이 유사하였다.\n",
    "\n",
    "많은 사람들의 synthesis에서 다음과 같은 경우를 보았다. 처음엔 아무런 payoff가 없다가 그들이 어떤 trick을 발견하면 성능이 아주 잘 나오는 것이다. \n",
    "\n",
    "다른 예로는 speech recognition이 있는데 clean audio에선 성능이 잘 나오는 것에 그냥 background noise를 더하는 것이다. 이것은 sound wave의 중첩 특성을 이용한 것이다. 이러면 차 안에서 말하는 소리라던지 많은 양의 데이터를 만들 수 있다. \n",
    "\n",
    "다른 예로 NLP에서 grammar correction이 있다. 영어 문장에 random grammar를 더하는 것이다. random grammatical effect, random grammatical error를 보는 것이다. 인공지능이 ungrammatical sentence를 고치게 하는 것이다.\n",
    "\n",
    "Noise synthesis를 보자, 우리 팀은 10,000 hours의 clean audio data를 가지고 있고 10 hours 의 noise(inside car, cafe 등)를 가지고 있따. clean audio만 가지고 학습하면 overfitting이 되기 쉽다. 그러나 noise를 추가하면 많은 다른 경우를 만들 수 있다.\n",
    "\n",
    "다른 경우로는 recognize car가 있다. 어디서 많은 양의 car picture data를 얻을 것인가 예를 들어 GTA란 게임을 보자 거기엔 많은 양의 차량이 있다 거기서 얻어 보는 것은 어떤가 게임에는 20종류의 모델의 차량이 있다. 실제 게임을 해본다면 차가 20종류 밖에 안되는 것을 알지 못할 것이다. 실제 현실에는 20종류보다는 훨씬 많은 종류의 차량이 있다. 인간의 눈으로 봤을 땐 잘 모르지만 인공지능 모델에선 쉽게 overfitting된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train과 test set이 같은 distribution에서 나오면 이론을 증명하는데 더 좋을 것이다. 한 가지 예를 보자 당신은 speech enabled rear mirror 상품을 만들려고 하고 있다. 당신은 real mirror에게 스타벅스에 가는 데 방향을 알려줘라고 말할 수 있을 것이다. \n",
    "\n",
    "어떻게 speech recognition system을 만들 것인가   \n",
    "당신은 50,000 시간의 general speech data를 가지고 있을 수 있다.   \n",
    "거기에 추가로 10 시간의 rear view mirro data를 모았을 수도 있다.   \n",
    "문제는 이거다. 어떻게 이 문제에 대한 training,development,test set을 를 정의할 것인가\n",
    "\n",
    "한 가지 방법으로   \n",
    "50,000 시간 데이터를 쪼개 train과 dev로 만들고   \n",
    "10 시간 데이터를 test로 쓰는 방법이 있다.   \n",
    "이 방법은 안 좋은 것으로 밝혀졌다. 왜냐하면 test set과 dev set이 같은 distribution에서 나오지 않았기 때문이다. 우리가 신경써야할 test distribution에 generalize하지 못 했다. \n",
    "\n",
    "추천하는 방법으로는\n",
    "50,000 시간 데이터 중 작은 부분을 train-dev set으로 만들고   \n",
    "10 시간 데이터를 쪼개 dev,test set으로 만드는 것이다. 여기서 중요한 것은 dev와 test set이 같은 distribution에서 나왔다는 것이다. dev, test set를 단지 평가용으로 꽤 작게 설정하는데 성능을 향상시킬만큼 충분한 양이 있어야 한다. \n",
    "\n",
    "예를 들어 다음과 같이 error가 나왔다고 하자.\n",
    "Human level error 1%   \n",
    "Training 10%   \n",
    "Training-Dev 10%\n",
    "Dev 10%\n",
    "Test 10%   \n",
    "\n",
    "Human level과 training의 차이는 bias이다. avoidable bias이다. Training과 Training-Dev의 차이는 variance이다. 다시 말하지만 training과 train-dev는 같은 distribution에서 나왔다. Training-dev와 Dev의 차이는 data mismatch issue이다. Training-Dev와 Dev 둘 다 훈련에 사용되지 않았지만 다른 Distribution에서 나왔다. 마지막으로 Dev와 Test의 차이는 overfit dev set이다. Dev와 Test는 같은 Distribution에서 나왔다.\n",
    "\n",
    "다른 예로\n",
    "Human level error 1%   \n",
    "Training 1%   \n",
    "Training-Dev 2%\n",
    "Dev 10%\n",
    "Test 11%\n",
    "\n",
    "당신은 Training-Dev와 Dev 사이의 엄청난 gap을 볼 수 있을 것이다. 이것은 당신의 에러 대부분이 data mismatch에서 왔음을 알 수 있다.\n",
    "\n",
    "에러를 수정하는 방법을 보자면\n",
    "1. Training error(Bias Problem)   \n",
    "    Bigger Model, Train longer, New Model Architecture\n",
    "       \n",
    "       \n",
    "2. Training-Dev error(Variance Problem)   \n",
    "    같은 Distribution에서 나온 것도 제대로 못 함   \n",
    "    More Data, Regularization, New Model Architecture\n",
    "       \n",
    "       \n",
    "3. Dev error(Data Mismatch)   \n",
    "    다른 Distribution   \n",
    "    Make data more similar, Data synthesis, domain adaptation, New Model architecture)\n",
    "    \n",
    "       \n",
    "4. Test error(overfit dev set)   \n",
    "    같은 Distribution    \n",
    "    More dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". | General speech data(50,000H) | In-Car data(10H) | Partner\n",
    "-|-|-|-\n",
    "Human-level|Human-level|.|.\n",
    "Ref on seen examples | Training error |.|.\n",
    "Ref on unseen examples | Training-Dev error | Dev/test error|."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Product Management\n",
    "Product Manager(PM) is responsible for figuring out what products users really want\n",
    "How big the size the image, How important is latency\n",
    "\n",
    "User - PM - Engineer\n",
    "\n",
    "PM은 유저가 원하는 것을 알고 엔지니어에게 전달한다(구체적으로 이런 버튼이 여기에 이런 크기로 있었으면 좋겠고 이 버튼은 여기에....) \n",
    "\n",
    "AI에서는 상품을 뭘로 정의할것인지, 어떻게 디자인할 것인지 정하는 게 중요하다\n",
    "\n",
    "예를 들어 speech recognition을 보자 당신은 성능을 향상시키는 데 어떤 걸 향상시켜야할지 정해야 한다. 어떤 걸 제일 먼저 주력해서 해야할 지 정해야한다.\n",
    "* Noisy environment(Car, Cafe)\n",
    "* Low bandwidth audio\n",
    "* accented speech\n",
    "* Latency\n",
    "* binary size(모바일 환경에서는 큰 용량을 사용하기 힘듬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
